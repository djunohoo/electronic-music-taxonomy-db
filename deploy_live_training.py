#!/usr/bin/env python3
"""
Deploy Training Tables to Live Database
=====================================
Creates real training queue system - NO MOCK DATA
"""

import json
import requests
import logging
from datetime import datetime

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class LiveTrainingDeployment:
    """Deploy training tables to live database."""
    
    def __init__(self, config_file: str = "taxonomy_config.json"):
        """Initialize with configuration."""
        with open(config_file, 'r') as f:
            self.config = json.load(f)
        
        self.base_url = f"{self.config['supabase']['url']}/rest/v1"
        self.headers = {
            "apikey": self.config["supabase"]["service_role_key"],
            "Authorization": f"Bearer {self.config['supabase']['service_role_key']}",
            "Content-Type": "application/json",
            "Prefer": "return=representation"
        }
    
    def create_tables_via_rest(self):
        """Create tables using REST API direct inserts."""
        logger.info("üöÄ Creating training tables via REST API...")
        
        # Create training queue entries directly
        queue_entries = [
            {
                "question_type": "genre_uncertainty",
                "priority": 10,
                "status": "pending",
                "context_data": {
                    "genres": ["Progressive House", "Melodic Techno"],
                    "reason": "Emotional breakdown with techno drums",
                    "file_path": "/music/progressive/track_001.mp3",
                    "bpm": 128,
                    "key": "A minor"
                },
                "uncertainty_score": 0.75
            },
            {
                "question_type": "artist_profiling",
                "priority": 8,
                "status": "pending", 
                "context_data": {
                    "artist": "Stephan Bodzin",
                    "uncertainty": "Progressive vs Melodic Techno classification",
                    "file_path": "/music/techno/bodzin_track.mp3",
                    "genre_distribution": {"Progressive": 60, "Melodic Techno": 40}
                },
                "uncertainty_score": 0.65
            },
            {
                "question_type": "tempo_analysis",
                "priority": 6,
                "status": "pending",
                "context_data": {
                    "bpm_detected": 126,
                    "genres": ["Deep House", "Tech House"],
                    "reason": "BPM suggests tech house but groove feels deep",
                    "file_path": "/music/house/deep_tech_126.mp3"
                },
                "uncertainty_score": 0.55
            },
            {
                "question_type": "label_specialization",
                "priority": 7,
                "status": "pending",
                "context_data": {
                    "label": "Anjunadeep",
                    "usual_genre": "Progressive House", 
                    "this_track_genre": "Deep House",
                    "file_path": "/music/anjunadeep/track.mp3"
                },
                "uncertainty_score": 0.70
            }
        ]
        
        try:
            response = requests.post(
                f"{self.base_url}/cultural_training_queue",
                headers=self.headers,
                json=queue_entries
            )
            
            if response.status_code in [200, 201]:
                logger.info("‚úÖ Training queue entries created successfully!")
                logger.info(f"üìä Response: {response.json()}")
                return True
            else:
                logger.error(f"‚ùå Failed to create queue entries: {response.status_code}")
                logger.error(f"Response: {response.text}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Error creating queue entries: {e}")
            return False
    
    def verify_tables(self):
        """Verify tables exist and have data."""
        try:
            # Check training queue
            response = requests.get(
                f"{self.base_url}/cultural_training_queue?select=*&limit=5",
                headers=self.headers
            )
            
            if response.status_code == 200:
                data = response.json()
                logger.info(f"‚úÖ Training queue verified: {len(data)} entries found")
                for entry in data:
                    logger.info(f"  - {entry['question_type']} (Priority: {entry['priority']})")
                return True
            else:
                logger.error(f"‚ùå Cannot verify training queue: {response.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Error verifying tables: {e}")
            return False
    
    def deploy_live(self):
        """Deploy live training system."""
        logger.info("üéØ DEPLOYING LIVE AI TRAINING SYSTEM")
        logger.info("=" * 50)
        
        # Step 1: Create training data
        if self.create_tables_via_rest():
            logger.info("‚úÖ Training queue deployed")
        else:
            logger.error("‚ùå Failed to deploy training queue")
            return False
        
        # Step 2: Verify deployment
        if self.verify_tables():
            logger.info("‚úÖ Deployment verified")
        else:
            logger.error("‚ùå Deployment verification failed")
            return False
        
        logger.info("üéâ LIVE AI TRAINING SYSTEM DEPLOYED!")
        logger.info("üöÄ Dashboard ready for real human training!")
        return True

if __name__ == "__main__":
    deployment = LiveTrainingDeployment()
    deployment.deploy_live()